{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"dockerized Containerized development environments using Docker. Features Toolset as Code - Declare which build and/or development tools are needed in code, rather than in a README file. Your CI can use exactly the same toolset as your developers. Easy onboarding - Bootstrapping a development environment is as easy as running dockerized shell . No more \"Works on my machine\" - No more \"Works on my machine\" because everyone in the team is using exactly the same toolset. Consistency with CI - Your CI can use exactly the same toolset as your developers. Isolated environments - No need for nvm , virtualenv , SDKMAN , and such. Each development environment is isolated. Simple - You no longer need to maintain messy docker run commands yourself. Seamless - Just prepend any command with dockerized exec . Visual Studio Code - \"dockerized\" complements VS Code and can use the Remote Containers you already configured. Opt in - You can use the \"dockerized\" development environment, or set up one directly on your machine. Unlike other tools \"dockerized\" is a non-intrusive guest on your machine. Caching - \"dockerized\" can cache the build environment to speed up builds on CI pipelines. See the Quick Start tutorial to get started!","title":"Home"},{"location":"#dockerized","text":"Containerized development environments using Docker.","title":"dockerized"},{"location":"#features","text":"Toolset as Code - Declare which build and/or development tools are needed in code, rather than in a README file. Your CI can use exactly the same toolset as your developers. Easy onboarding - Bootstrapping a development environment is as easy as running dockerized shell . No more \"Works on my machine\" - No more \"Works on my machine\" because everyone in the team is using exactly the same toolset. Consistency with CI - Your CI can use exactly the same toolset as your developers. Isolated environments - No need for nvm , virtualenv , SDKMAN , and such. Each development environment is isolated. Simple - You no longer need to maintain messy docker run commands yourself. Seamless - Just prepend any command with dockerized exec . Visual Studio Code - \"dockerized\" complements VS Code and can use the Remote Containers you already configured. Opt in - You can use the \"dockerized\" development environment, or set up one directly on your machine. Unlike other tools \"dockerized\" is a non-intrusive guest on your machine. Caching - \"dockerized\" can cache the build environment to speed up builds on CI pipelines. See the Quick Start tutorial to get started!","title":"Features"},{"location":"explanations/how_dockerized_exec_works/","text":"How \"dockerized exec\" works dockerized is a thin wrapper around Docker Compose. Every dockerized project contains a .dockerized/ directory that contains a docker-compose.dockerized.yml at minimum. That file essentially describes the development environment. It contains at least one \u201cservice\u201d called \u201cdockerized\u201d. When you run dockerized exec COMMAND (for example, dockerized exec make build ), dockerized runs docker-compose ... run dockerized COMMAND . To make it feel as if you are executing the command in the current directory (only in an environment that has all the tools that command needs), dockerized bind-mounts the project directory and sets the working directory accordingly. To see the exact arguments it passes set the log level to INFO: > dockerized --loglevel = INFO exec ls -l INFO:dockerized.core.commands.dockercomposecommand:Configuration file ( /Users/benzaita/dev/sandbox/.dockerized/config.yml ) does not exist. Using defaults. INFO:dockerized.core.project:/Users/benzaita/dev/sandbox is prepared INFO:dockerized.adapters.dockercompose:Running: [ 'docker-compose' , '-f' , '/Users/benzaita/dev/sandbox/.dockerized/docker-compose.dockerized.yml' , '--project-name' , '/Users/benzaita/dev/sandbox' , 'run' , '--rm' , '--service-ports' , '-v' , '/Users/benzaita/dev/sandbox:/Users/benzaita/dev/sandbox' , '-w' , '/Users/benzaita/dev/sandbox' , 'dockerized' , 'ls -l' ] Note that every time you run a command, dockerized spawns a new \"one-off\" container that is removed when the command is completed.","title":"How \"dockerized exec\" works"},{"location":"explanations/how_dockerized_exec_works/#how-dockerized-exec-works","text":"dockerized is a thin wrapper around Docker Compose. Every dockerized project contains a .dockerized/ directory that contains a docker-compose.dockerized.yml at minimum. That file essentially describes the development environment. It contains at least one \u201cservice\u201d called \u201cdockerized\u201d. When you run dockerized exec COMMAND (for example, dockerized exec make build ), dockerized runs docker-compose ... run dockerized COMMAND . To make it feel as if you are executing the command in the current directory (only in an environment that has all the tools that command needs), dockerized bind-mounts the project directory and sets the working directory accordingly. To see the exact arguments it passes set the log level to INFO: > dockerized --loglevel = INFO exec ls -l INFO:dockerized.core.commands.dockercomposecommand:Configuration file ( /Users/benzaita/dev/sandbox/.dockerized/config.yml ) does not exist. Using defaults. INFO:dockerized.core.project:/Users/benzaita/dev/sandbox is prepared INFO:dockerized.adapters.dockercompose:Running: [ 'docker-compose' , '-f' , '/Users/benzaita/dev/sandbox/.dockerized/docker-compose.dockerized.yml' , '--project-name' , '/Users/benzaita/dev/sandbox' , 'run' , '--rm' , '--service-ports' , '-v' , '/Users/benzaita/dev/sandbox:/Users/benzaita/dev/sandbox' , '-w' , '/Users/benzaita/dev/sandbox' , 'dockerized' , 'ls -l' ] Note that every time you run a command, dockerized spawns a new \"one-off\" container that is removed when the command is completed.","title":"How \"dockerized exec\" works"},{"location":"explanations/why_use_dockerized/","text":"Why use dockerized dockerized is a command-line tool that lets you seamlessly execute commands in a container. You can just prepend any command with dockerized exec to have it run inside your container. It's especially helpful for keeping your build dependencies in a Dockerfile. Think of it as env but for Docker. It supports caching of the Docker image and even VSCode Remote Containers ! Quick Glance In a nutshell, instead of running a command like this (relying on the user to use the correct version of Node.js and Yarn): yarn install you just pass it to dockerized: dockerized exec yarn install dockerized will run that command in a container with the correct build tools. Why you should keep your build dependencies in a Dockerfile Easy onboarding - when a new team member joins you want them to be able to contribute as fast as possible. You don't want them to spend hours/days trying to follow an outdated README file, installing build tools, and setting up their machine. Ideally, they should be able to jump in with a minimal amount of preparation. Consistency - Works on My Machine (tm) but breaks on the CI/CD pipeline? Your local development environment cannot be identical to the CI/CD environment, but it should be as close as possible. If both environments use the same Dockerfile to run the build, you minimize the gap between the two. Conflicting dependencies - one project requires Java 8 and the other Java 10? Does one project require Node 10 and the other Node 12? Python? True, there is JAVA_HOME and nvm and whatever for Python, but try forgetting to set JAVA_HOME when switching a directory only to find fifteen minutes later that you are not crazy, just forgetful. And while avn can automatically switch Node versions when you cd to another directory, it is yet another tool the developer needs to install. Worse, if they don't - the risk using the wrong Node version without even knowing. What I've seen people usually do (and have done by myself) I've seen projects that rely on verbal communication and \"folk tales\" to have a common understanding of what the build-environment is. That should be obvious why it's bad. I've seen projects that use a README to document what the bulid-environment is. That usually ends up with an outdated README file that nobody really follows. I've seen projects that have a huge Dockerfile that contains all the build dependencies for all the projects of the team because \"they all run in Jenkins eventually\". I've seen projects that have a proper Dockerfile with the build dependencies, but in a different repository. That's better, but it is hard to coordinate changes between the two repos (albeit, to be fair, these do not often happen). And I've seen projects that have a proper Dockerfile with the build dependencies, in the same repo! However, these usually also require some \"wrapper\" script to pass all the flags to Docker - the volumes to map, the environment variables, the network mode, the working directory, etc. Why is that bad? For once, you need to re-write this wrapper for every repository. Secondly, these wrapper scripts tend to hide the CLIs of the tools they are running - instead of running mvn -DskipTests package you need to run make package . And when things break, and you need an interactive shell to figure out what went wrong, I usually resorted to docker run --entrypoint /bin/sh .... (or make shell if I was not lazy). What do you get with dockerized? With dockerized you can just do dockerized exec mvn -DskipTests package , or dockerized exec COMMAND with whatever COMMAND you need. Need an interactive shell inside the container? Just run dockerized shell . dockerized takes care of building the container when necessary, mapping volumes, setting the working directory, and more. It does not, however, hide the interface of the tool you are trying to run.","title":"Why use dockerized"},{"location":"explanations/why_use_dockerized/#why-use-dockerized","text":"dockerized is a command-line tool that lets you seamlessly execute commands in a container. You can just prepend any command with dockerized exec to have it run inside your container. It's especially helpful for keeping your build dependencies in a Dockerfile. Think of it as env but for Docker. It supports caching of the Docker image and even VSCode Remote Containers !","title":"Why use dockerized"},{"location":"explanations/why_use_dockerized/#quick-glance","text":"In a nutshell, instead of running a command like this (relying on the user to use the correct version of Node.js and Yarn): yarn install you just pass it to dockerized: dockerized exec yarn install dockerized will run that command in a container with the correct build tools.","title":"Quick Glance"},{"location":"explanations/why_use_dockerized/#why-you-should-keep-your-build-dependencies-in-a-dockerfile","text":"Easy onboarding - when a new team member joins you want them to be able to contribute as fast as possible. You don't want them to spend hours/days trying to follow an outdated README file, installing build tools, and setting up their machine. Ideally, they should be able to jump in with a minimal amount of preparation. Consistency - Works on My Machine (tm) but breaks on the CI/CD pipeline? Your local development environment cannot be identical to the CI/CD environment, but it should be as close as possible. If both environments use the same Dockerfile to run the build, you minimize the gap between the two. Conflicting dependencies - one project requires Java 8 and the other Java 10? Does one project require Node 10 and the other Node 12? Python? True, there is JAVA_HOME and nvm and whatever for Python, but try forgetting to set JAVA_HOME when switching a directory only to find fifteen minutes later that you are not crazy, just forgetful. And while avn can automatically switch Node versions when you cd to another directory, it is yet another tool the developer needs to install. Worse, if they don't - the risk using the wrong Node version without even knowing.","title":"Why you should keep your build dependencies in a Dockerfile"},{"location":"explanations/why_use_dockerized/#what-ive-seen-people-usually-do-and-have-done-by-myself","text":"I've seen projects that rely on verbal communication and \"folk tales\" to have a common understanding of what the build-environment is. That should be obvious why it's bad. I've seen projects that use a README to document what the bulid-environment is. That usually ends up with an outdated README file that nobody really follows. I've seen projects that have a huge Dockerfile that contains all the build dependencies for all the projects of the team because \"they all run in Jenkins eventually\". I've seen projects that have a proper Dockerfile with the build dependencies, but in a different repository. That's better, but it is hard to coordinate changes between the two repos (albeit, to be fair, these do not often happen). And I've seen projects that have a proper Dockerfile with the build dependencies, in the same repo! However, these usually also require some \"wrapper\" script to pass all the flags to Docker - the volumes to map, the environment variables, the network mode, the working directory, etc. Why is that bad? For once, you need to re-write this wrapper for every repository. Secondly, these wrapper scripts tend to hide the CLIs of the tools they are running - instead of running mvn -DskipTests package you need to run make package . And when things break, and you need an interactive shell to figure out what went wrong, I usually resorted to docker run --entrypoint /bin/sh .... (or make shell if I was not lazy).","title":"What I've seen people usually do (and have done by myself)"},{"location":"explanations/why_use_dockerized/#what-do-you-get-with-dockerized","text":"With dockerized you can just do dockerized exec mvn -DskipTests package , or dockerized exec COMMAND with whatever COMMAND you need. Need an interactive shell inside the container? Just run dockerized shell . dockerized takes care of building the container when necessary, mapping volumes, setting the working directory, and more. It does not, however, hide the interface of the tool you are trying to run.","title":"What do you get with dockerized?"},{"location":"how_to_guides/cache_the_dockerized_docker_image/","text":"Cache the \u201cdockerized\u201d Docker image When running in CI dockerized probably runs on a fresh node where the \"dockerized\" image is not available yet. Therefore, it needs to build it from scratch. This can be a long process of downloading and installing build dependencies. Doing this over and over again on every fresh node is wasteful. Let's illustrate this using the following ./dockerized/Dockerfile.dockerized file: FROM busybox RUN echo \"long operation\" Configuring to pull the cache image Make the following changes to your ./dockerized/docker-compose.dockerized.yml file: version : '3.2' services : dockerized : image : benzaita/dockerized-fixture-with_build_cache build : context : . dockerfile : Dockerfile.dockerized cache_from : - benzaita/dockerized-fixture-with_build_cache entrypoint : - sh - '-c' dockerized first tries to pulls the dockerized image before building it so Docker can utilize it. If the image was built using the same Dockerfile, Docker will use the cache from benzaita/dockerized-fixture-with_build_cache instead of executing the RUN echo \"long operation\" line during build. When you run a command using dockerized exec you can expect the following: Pulling dockerized ... done Building dockerized ... Step 2/2 : RUN echo \"long operation\" ---> Using cache ... Pushing the cache image Having a remote cache for the image means you need to decide when to update it -- when to run dockerized push . It is recommended to run dockerized push at the end of your CI pipeline. This ensures that (a) the pipeline successfully runs with this dockerized image (so you don't push a broken image) and (b) incurs a very small overhead since in most of the builds the Docker image is already up to date and Docker does not push the layers. Another option is to let the developer run dockerized push after they commit a change to the .dockerized/Dockerfile.dockerized file. This does not require any automation, but means the developer might forget to do it, rendering the cache out of date.","title":"Cache the \"dockerized\" Docker image"},{"location":"how_to_guides/cache_the_dockerized_docker_image/#cache-the-dockerized-docker-image","text":"When running in CI dockerized probably runs on a fresh node where the \"dockerized\" image is not available yet. Therefore, it needs to build it from scratch. This can be a long process of downloading and installing build dependencies. Doing this over and over again on every fresh node is wasteful. Let's illustrate this using the following ./dockerized/Dockerfile.dockerized file: FROM busybox RUN echo \"long operation\"","title":"Cache the \u201cdockerized\u201d Docker image"},{"location":"how_to_guides/cache_the_dockerized_docker_image/#configuring-to-pull-the-cache-image","text":"Make the following changes to your ./dockerized/docker-compose.dockerized.yml file: version : '3.2' services : dockerized : image : benzaita/dockerized-fixture-with_build_cache build : context : . dockerfile : Dockerfile.dockerized cache_from : - benzaita/dockerized-fixture-with_build_cache entrypoint : - sh - '-c' dockerized first tries to pulls the dockerized image before building it so Docker can utilize it. If the image was built using the same Dockerfile, Docker will use the cache from benzaita/dockerized-fixture-with_build_cache instead of executing the RUN echo \"long operation\" line during build. When you run a command using dockerized exec you can expect the following: Pulling dockerized ... done Building dockerized ... Step 2/2 : RUN echo \"long operation\" ---> Using cache ...","title":"Configuring to pull the cache image"},{"location":"how_to_guides/cache_the_dockerized_docker_image/#pushing-the-cache-image","text":"Having a remote cache for the image means you need to decide when to update it -- when to run dockerized push . It is recommended to run dockerized push at the end of your CI pipeline. This ensures that (a) the pipeline successfully runs with this dockerized image (so you don't push a broken image) and (b) incurs a very small overhead since in most of the builds the Docker image is already up to date and Docker does not push the layers. Another option is to let the developer run dockerized push after they commit a change to the .dockerized/Dockerfile.dockerized file. This does not require any automation, but means the developer might forget to do it, rendering the cache out of date.","title":"Pushing the cache image"},{"location":"how_to_guides/pass_environment_variables/","text":"Pass Environment Variables When running dockerized exec COMMAND , there are two ways to pass environment variables to COMMAND . In the Command Line The easiest way is to prepend the COMMAND with them: dockerized exec FOO = 1 BAR = 2 COMMAND For example > dockerized exec FOO = 1 BAR = 2 env ... FOO = 1 BAR = 2 Using Docker-Compose You can define environment variables in the .dockerized/docker-compose.dockerized.yml file. This is useful if you keep passing the same variables over and over, or if you don't want to have them present in the command line (for example because it is logged). Here is an example: version : '2' services : dockerized : build : context : . dockerfile : Dockerfile.dockerized entrypoint : - sh - '-c' environment : - FOO=1 # specify a value - SECRET # pass the variable from the host environment","title":"Pass Environment Variables"},{"location":"how_to_guides/pass_environment_variables/#pass-environment-variables","text":"When running dockerized exec COMMAND , there are two ways to pass environment variables to COMMAND .","title":"Pass Environment Variables"},{"location":"how_to_guides/pass_environment_variables/#in-the-command-line","text":"The easiest way is to prepend the COMMAND with them: dockerized exec FOO = 1 BAR = 2 COMMAND For example > dockerized exec FOO = 1 BAR = 2 env ... FOO = 1 BAR = 2","title":"In the Command Line"},{"location":"how_to_guides/pass_environment_variables/#using-docker-compose","text":"You can define environment variables in the .dockerized/docker-compose.dockerized.yml file. This is useful if you keep passing the same variables over and over, or if you don't want to have them present in the command line (for example because it is logged). Here is an example: version : '2' services : dockerized : build : context : . dockerfile : Dockerfile.dockerized entrypoint : - sh - '-c' environment : - FOO=1 # specify a value - SECRET # pass the variable from the host environment","title":"Using Docker-Compose"},{"location":"how_to_guides/provide_aws_credentials/","text":"Provide AWS Credentials Your dockerized development environment may need AWS credentials. There are a few options to provide these: Option 1: Pass environment variables Configure the dockerized environment to use the AWS_* variables from the host environment. Add this to the .dockerized/docker-compose.dockerized.yml file: dockerized: environment: - AWS_ACCESS_KEY_ID - AWS_SECRET_ACCESS_KEY - AWS_SESSION_TOKEN Option 2: Mount the credentials file If you use multiple AWS profiles, you need to mount the AWS credentials file. Add this to the .dockerized/docker-compose.dockerized.yml file: dockerized: volumes: - ~/.aws/credentials:/root/.aws/credentials:ro","title":"Provide AWS Credentials"},{"location":"how_to_guides/provide_aws_credentials/#provide-aws-credentials","text":"Your dockerized development environment may need AWS credentials. There are a few options to provide these:","title":"Provide AWS Credentials"},{"location":"how_to_guides/provide_aws_credentials/#option-1-pass-environment-variables","text":"Configure the dockerized environment to use the AWS_* variables from the host environment. Add this to the .dockerized/docker-compose.dockerized.yml file: dockerized: environment: - AWS_ACCESS_KEY_ID - AWS_SECRET_ACCESS_KEY - AWS_SESSION_TOKEN","title":"Option 1: Pass environment variables"},{"location":"how_to_guides/provide_aws_credentials/#option-2-mount-the-credentials-file","text":"If you use multiple AWS profiles, you need to mount the AWS credentials file. Add this to the .dockerized/docker-compose.dockerized.yml file: dockerized: volumes: - ~/.aws/credentials:/root/.aws/credentials:ro","title":"Option 2: Mount the credentials file"},{"location":"how_to_guides/use_with_vscode_remote_containers/","text":"Use with VSCode Remote Containers VSCode Remote Containers allows you to define a development environment in Docker, just like dockerized. However, in a build server environment you are probably not running VSCode. dockerized can be configured to use the development environment defined by VSCode Remote Containers, so you can use them outside VSCode. VSCode defines the development environment in a .devcontainer directory using a Dockerfile and possibly a docker-compose.yml file, very similarly to dockerized. To configure dockerized to use that environment follow these instructions: When the .devcontainer directory contains only a Dockerfile Run this to initialize your dockerized project: dockerized init --from https://github.com/benzaita/dockerized-example-vscode.git When the .devcontainer directory contains both Dockerfile and docker-compose.yml Run this to initialize your dockerized project: dockerized init --from https://github.com/benzaita/dockerized-example-vscode-docker-compose.git","title":"Use with VSCode Remote Containers"},{"location":"how_to_guides/use_with_vscode_remote_containers/#use-with-vscode-remote-containers","text":"VSCode Remote Containers allows you to define a development environment in Docker, just like dockerized. However, in a build server environment you are probably not running VSCode. dockerized can be configured to use the development environment defined by VSCode Remote Containers, so you can use them outside VSCode. VSCode defines the development environment in a .devcontainer directory using a Dockerfile and possibly a docker-compose.yml file, very similarly to dockerized. To configure dockerized to use that environment follow these instructions:","title":"Use with VSCode Remote Containers"},{"location":"how_to_guides/use_with_vscode_remote_containers/#when-the-devcontainer-directory-contains-only-a-dockerfile","text":"Run this to initialize your dockerized project: dockerized init --from https://github.com/benzaita/dockerized-example-vscode.git","title":"When the .devcontainer directory contains only a Dockerfile"},{"location":"how_to_guides/use_with_vscode_remote_containers/#when-the-devcontainer-directory-contains-both-dockerfile-and-docker-composeyml","text":"Run this to initialize your dockerized project: dockerized init --from https://github.com/benzaita/dockerized-example-vscode-docker-compose.git","title":"When the .devcontainer directory contains both Dockerfile and docker-compose.yml"},{"location":"how_to_guides/utilize_package_managers_cache/","text":"Utilize Package-Managers Cache Suppose you have a build container that has Yarn installed. When you run yarn inside that container Yarn has to download the Yarn packages even if it already downloaded them in a previous run. To resolve this, the cache needs to be persisted between runs. The same is true for most of the package managers - Yarn, Maven, Gradle, Pip, ... In the next sections, you can find recipes for persisting the cache directory of each package manager. Yarn Add this to your .dockerized/docker-compose.dockerized.yml : services : dockerized : environment : - YARN_CACHE_FOLDER=/data/yarn-cache volumes : - 'yarn-cache:/data/yarn-cache' volumes : yarn-cache : {} Maven Add this to your .dockerized/docker-compose.dockerized.yml : services : dockerized : volumes : - maven-cache:/root/.m2 volumes : maven-cache : {} Gradle Add this to your .dockerized/docker-compose.dockerized.yml : services : dockerized : volumes : - gradle-cache:/root/.gradle volumes : gradle-cache : {} Pip Add this to your .dockerized/docker-compose.dockerized.yml : services : dockerized : volumes : - pip-cache:/root/.cache/pip volumes : pip-cache : {}","title":"Utilize Package-Managers Cache"},{"location":"how_to_guides/utilize_package_managers_cache/#utilize-package-managers-cache","text":"Suppose you have a build container that has Yarn installed. When you run yarn inside that container Yarn has to download the Yarn packages even if it already downloaded them in a previous run. To resolve this, the cache needs to be persisted between runs. The same is true for most of the package managers - Yarn, Maven, Gradle, Pip, ... In the next sections, you can find recipes for persisting the cache directory of each package manager.","title":"Utilize Package-Managers Cache"},{"location":"how_to_guides/utilize_package_managers_cache/#yarn","text":"Add this to your .dockerized/docker-compose.dockerized.yml : services : dockerized : environment : - YARN_CACHE_FOLDER=/data/yarn-cache volumes : - 'yarn-cache:/data/yarn-cache' volumes : yarn-cache : {}","title":"Yarn"},{"location":"how_to_guides/utilize_package_managers_cache/#maven","text":"Add this to your .dockerized/docker-compose.dockerized.yml : services : dockerized : volumes : - maven-cache:/root/.m2 volumes : maven-cache : {}","title":"Maven"},{"location":"how_to_guides/utilize_package_managers_cache/#gradle","text":"Add this to your .dockerized/docker-compose.dockerized.yml : services : dockerized : volumes : - gradle-cache:/root/.gradle volumes : gradle-cache : {}","title":"Gradle"},{"location":"how_to_guides/utilize_package_managers_cache/#pip","text":"Add this to your .dockerized/docker-compose.dockerized.yml : services : dockerized : volumes : - pip-cache:/root/.cache/pip volumes : pip-cache : {}","title":"Pip"},{"location":"reference/starter_kits/","text":"Starter Kits To start using dockerized you can either initialize an empty project using dockerized init , or use a \u201cstarter kit\u201d. A starter kit is a predefined environment that you can customize. To initialize a project using a starter kit use: dockerized init --from <GIT REPOSITORY URL> Here are a couple of starter kits which are available: Python dockerized init --from https://github.com/benzaita/dockerized-example-python.git Go dockerized init --from https://github.com/benzaita/dockerized-example-golang.git Node.js dockerized init --from https://github.com/benzaita/dockerized-example-nodejs.git VSCode If you are using VSCode Remote Containers, and your .devcontainer/ is using only a Dockerfile file (without a docker-compose.yml file): dockerized init --from https://github.com/benzaita/dockerized-example-vscode.git And if your .devcontainer/ contains both Dockerfile and docker-compose.yml files: dockerized init --from https://github.com/benzaita/dockerized-example-vscode-docker-compose.git Open an issue to suggest more!","title":"Starter Kits"},{"location":"reference/starter_kits/#starter-kits","text":"To start using dockerized you can either initialize an empty project using dockerized init , or use a \u201cstarter kit\u201d. A starter kit is a predefined environment that you can customize. To initialize a project using a starter kit use: dockerized init --from <GIT REPOSITORY URL> Here are a couple of starter kits which are available:","title":"Starter Kits"},{"location":"reference/starter_kits/#python","text":"dockerized init --from https://github.com/benzaita/dockerized-example-python.git","title":"Python"},{"location":"reference/starter_kits/#go","text":"dockerized init --from https://github.com/benzaita/dockerized-example-golang.git","title":"Go"},{"location":"reference/starter_kits/#nodejs","text":"dockerized init --from https://github.com/benzaita/dockerized-example-nodejs.git","title":"Node.js"},{"location":"reference/starter_kits/#vscode","text":"If you are using VSCode Remote Containers, and your .devcontainer/ is using only a Dockerfile file (without a docker-compose.yml file): dockerized init --from https://github.com/benzaita/dockerized-example-vscode.git And if your .devcontainer/ contains both Dockerfile and docker-compose.yml files: dockerized init --from https://github.com/benzaita/dockerized-example-vscode-docker-compose.git Open an issue to suggest more!","title":"VSCode"},{"location":"tutorials/quick_start/","text":"Quick Start Welcome! dockerized is a CLI tool for creating and using containerized development environments using Docker. In this tutorial you will learn: How to install dockerized How to define a development environment How to run commands in the containerized development environment Let\u2019s get started! Installing dockerized dockerized is written in Python and available via pip: pip install dockerized You can verify the installation by running dockerized version . Initializing a project The first step we need to take is to initialize a new workspace, or project: > dockerized init created This creates a .dockerized/ directory in the current directory. Let\u2019s explore it: > ls .dockerized/ Dockerfile.dockerized docker-compose.dockerized.yml These two files define the development environment -- the Dockerfile defines which tools are required (e.g. python, git, jq, make) and the docker-compose file defines which services it consists of. Currently our environment does not require any tools: > cat .dockerized/Dockerfile.dockerized FROM busybox # Add your build dependencies here And contains only a single service, \u201cdockerized\u201d, where our commands will run: > cat .dockerized/docker-compose.dockerized.yml version: '3.2' services: dockerized: build: context: . dockerfile: Dockerfile.dockerized entrypoint: - sh - '-c' Defining the development environment Let\u2019s assume our project requires Node.js 14 and jq. Edit the .dockerized/Dockerfile.dockerized file and set its contents to: FROM node:14 RUN apt-get update \\ && apt-get install -y jq Run this to verify we have both Node.js and jq: > dockerized exec jq jq - commandline JSON processor [ version 1 .5-1-a5b5cbe ] --snip-- > dockerized exec node --version v14.17.0 Running commands inside the development environment Let\u2019s run something inside the containerized development environment now: > echo 'console.log(\"Hello world!\")' > main.js > dockerized exec node main.js Hello world! To pass environment variables to the container, use this: > echo 'console.log(\"Hello \" + process.env[\"USER\"])' > main.js > dockerized exec USER = Alice node main.js Hello Alice See also the Pass environment variables how-to guide.","title":"Quick Start"},{"location":"tutorials/quick_start/#quick-start","text":"Welcome! dockerized is a CLI tool for creating and using containerized development environments using Docker. In this tutorial you will learn: How to install dockerized How to define a development environment How to run commands in the containerized development environment Let\u2019s get started!","title":"Quick Start"},{"location":"tutorials/quick_start/#installing-dockerized","text":"dockerized is written in Python and available via pip: pip install dockerized You can verify the installation by running dockerized version .","title":"Installing dockerized"},{"location":"tutorials/quick_start/#initializing-a-project","text":"The first step we need to take is to initialize a new workspace, or project: > dockerized init created This creates a .dockerized/ directory in the current directory. Let\u2019s explore it: > ls .dockerized/ Dockerfile.dockerized docker-compose.dockerized.yml These two files define the development environment -- the Dockerfile defines which tools are required (e.g. python, git, jq, make) and the docker-compose file defines which services it consists of. Currently our environment does not require any tools: > cat .dockerized/Dockerfile.dockerized FROM busybox # Add your build dependencies here And contains only a single service, \u201cdockerized\u201d, where our commands will run: > cat .dockerized/docker-compose.dockerized.yml version: '3.2' services: dockerized: build: context: . dockerfile: Dockerfile.dockerized entrypoint: - sh - '-c'","title":"Initializing a project"},{"location":"tutorials/quick_start/#defining-the-development-environment","text":"Let\u2019s assume our project requires Node.js 14 and jq. Edit the .dockerized/Dockerfile.dockerized file and set its contents to: FROM node:14 RUN apt-get update \\ && apt-get install -y jq Run this to verify we have both Node.js and jq: > dockerized exec jq jq - commandline JSON processor [ version 1 .5-1-a5b5cbe ] --snip-- > dockerized exec node --version v14.17.0","title":"Defining the development environment"},{"location":"tutorials/quick_start/#running-commands-inside-the-development-environment","text":"Let\u2019s run something inside the containerized development environment now: > echo 'console.log(\"Hello world!\")' > main.js > dockerized exec node main.js Hello world! To pass environment variables to the container, use this: > echo 'console.log(\"Hello \" + process.env[\"USER\"])' > main.js > dockerized exec USER = Alice node main.js Hello Alice See also the Pass environment variables how-to guide.","title":"Running commands inside the development environment"}]}